{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DnnWeaver v2.0 tutorial\n",
    "### The tutorial covers the basics of using DnnWeaver v2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import array\n",
    "\n",
    "from dnnweaver2.benchmarks import get_graph\n",
    "from dnnweaver2.simulator.accelerator import Accelerator\n",
    "from dnnweaver2.compiler import *\n",
    "from dnnweaver2.fpga.fpgamanager import FPGAManager\n",
    "\n",
    "from dnnweaver2.scalar.dtypes import FixedPoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Express the DNN\n",
    "DnnWeaver v2.0 expresses DNNs as a graph, \n",
    "where the nodes are the operations/layers like convolution and edges are tensors\n",
    "\n",
    "The datatypes and bitwidths for the tensors are programmable\n",
    "By default, DnnWeaver 2.0 uses 16-bit fixed-point datatypes for all tensors\n",
    "\n",
    "The code snippe below expresses a single layers convolutional neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "List of ops (nodes) in the graph\n",
      "\tOp name: conv0/Convolution\n",
      "\tOp name: conv0/TypeCastOp\n",
      "\tOp name: pool1/MaxPooling\n",
      "**************************************************\n",
      "**************************************************\n",
      "List of tensors (edges) in the graph\n",
      "\tinputs/data[1,32,32,3] (FXP16 (8,8))\n",
      "\tconv0/weights[128,3,3,3] (FXP16 (4,12))\n",
      "\tconv0/biases[128] (FXP32 (12,20))\n",
      "\tconv0/Convolution[1,32,32,128] (FXP64 (44,20))\n",
      "\tconv0/TypeCastOp[1,32,32,128] (FXP16 (8,8))\n",
      "\tpool1/MaxPooling[1,16,16,128] (FXP16 (8,8))\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "graph = Graph('YOLOv2-Test: 16-bit', dataset='imagenet', log_level=logging.INFO)\n",
    "batch_size = 1\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "    with graph.name_scope('inputs'):\n",
    "        i = get_tensor(shape=(batch_size,32,32,3), name='data', dtype=FQDtype.FXP16, trainable=False)\n",
    "\n",
    "    with graph.name_scope('conv0'):\n",
    "        weights = get_tensor(shape=(128, 3, 3, 3),\n",
    "                             name='weights',\n",
    "                             dtype=FixedPoint(16,12))\n",
    "        biases = get_tensor(shape=(128),\n",
    "                             name='biases',\n",
    "                             dtype=FixedPoint(32,20))\n",
    "        conv = conv2D(i, weights, biases, pad='SAME', dtype=FixedPoint(16,8))\n",
    "    # DnnWeaver2 automatically takes care of type conversion\n",
    "    with graph.name_scope('pool1'):\n",
    "        pool = maxPool(conv, pooling_kernel=(1,2,2,1), stride=(1,2,2,1), pad='VALID')\n",
    "\n",
    "\n",
    "print('*'*50)\n",
    "print('List of ops (nodes) in the graph')\n",
    "# print the ops in the yolo2_graph\n",
    "for op in graph.op_registry:\n",
    "    print('\\tOp name: {}'.format(op))\n",
    "print('*'*50)\n",
    "    \n",
    "print('*'*50)\n",
    "print('List of tensors (edges) in the graph')\n",
    "# print the tensors in the yolo2_graph\n",
    "for tname, t in graph.tensor_registry.items():\n",
    "    print('\\t{}'.format(t))\n",
    "print('*'*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Compile the graph to generate instructions for the FPGA accelerator\n",
    "1. Define the accelerator object\n",
    "2. Optimize tiling for the accelerator and generate instruction binary for the accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accelerator object\n",
      "\tPrecision: 16\n",
      "\tSystolic array size: 32 -rows x 32 -columns\n",
      "\tIBUF size:     65,536 Bytes\n",
      "\tWBUF size:    524,288 Bytes\n",
      "\tOBUF size:    262,144 Bytes\n",
      "\tBBUF size:    131,072 Bytes\n",
      "Double buffering enabled. Sizes of SRAM are halved\n"
     ]
    }
   ],
   "source": [
    "# Step 2.1\n",
    "# on-chip BRAM buffers (number_bram * data_type * entries)\n",
    "num_rows = 32\n",
    "num_cols = 32\n",
    "bram = {\n",
    "    'ibuf':            num_cols * 16 * 2048 / 2,\n",
    "    'obuf':            num_rows * 64 * 2048 / 2,\n",
    "    'wbuf': num_cols * num_rows * 16 *  512 / 2,\n",
    "    'bbuf':            num_rows * 32 * 2048 / 2,\n",
    "}\n",
    "acc_obj = Accelerator(\n",
    "    N=num_rows, M=num_cols,\n",
    "    prec=16,\n",
    "    mem_if_width=256,\n",
    "    frequency=150e6,\n",
    "    sram=bram\n",
    ")\n",
    "\n",
    "print(acc_obj.__str__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instructions: 124\n"
     ]
    }
   ],
   "source": [
    "# Step 2.2\n",
    "log_level = logging.INFO\n",
    "compiler = GraphCompiler(log_level=log_level)\n",
    "inst_binary = compiler.compile(graph=graph, acc_obj=acc_obj)\n",
    "\n",
    "print('Number of instructions: {}'.format(inst_binary.size))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
